{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7488ea7-4b02-4536-8ea2-57689301f356",
   "metadata": {},
   "source": [
    "# PART 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235729be-4703-43ae-8296-abfa73dc2a7c",
   "metadata": {},
   "source": [
    "## Task 1: Classical ML with Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7d52ce8-4155-465e-9f18-0d9a5ebe0539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris Dataset Classification using Decision Tree\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce1f0890-dbb4-4901-a7d3-47284f3bfa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (assuming 'Iris.csv' is in the notebook directory)\n",
    "\n",
    "df = pd.read_csv(\"Iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "493ae24a-d5ca-48be-b4a3-3b31359d4667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Id column if exists\n",
    "df.drop(\"Id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66c3e136-c290-461b-a016-fc3d5516119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "df.fillna(df.mean(numeric_only=True), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6e9ad71-a92e-4d58-a24c-e285d53bf725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode species labels\n",
    "le = LabelEncoder()\n",
    "df['Species'] = le.fit_transform(df['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71dbf412-8aae-4668-a571-8dffa3bc2003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X = df.drop(\"Species\", axis=1)\n",
    "y = df[\"Species\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d25c680-3989-4d9b-b2ce-93b014c2ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ec24a21-7faf-4ce0-bfab-2d7af61eeed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Decision Tree model\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24e4cb74-c25a-4506-aec6-1edea5e1ee40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Predict and evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef76209-dc54-4807-ad98-1e4df2846104",
   "metadata": {},
   "source": [
    "## Task 2: Deep Learning with TensorFlow/PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40137fc1-6d61-4417-8913-6ba4a4ef6979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST CNN Classification with PyTorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00425961-7648-4f02-a220-0ae34d618281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Transform and Load Data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='.', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='.', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a49358-5ff1-4aab-b466-beedfa87cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define CNN Model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(64*5*5, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))         # [64, 32, 26, 26]\n",
    "        x = F.max_pool2d(x, 2)            # [64, 32, 13, 13]\n",
    "        x = F.relu(self.conv2(x))         # [64, 64, 11, 11]\n",
    "        x = F.max_pool2d(x, 2)            # [64, 64, 5, 5]\n",
    "        x = x.view(-1, 64*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "model = CNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf2d199e-e42f-42a5-a719-1b8493654822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Training Setup\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2faf645-18aa-4e17-bffa-465b0e10e3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed\n",
      "Epoch 2 completed\n",
      "Epoch 3 completed\n",
      "Epoch 4 completed\n",
      "Epoch 5 completed\n"
     ]
    }
   ],
   "source": [
    "# 4. Train the Model\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1} completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6df1c98a-3906-486a-8ceb-3f7c28c54a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.23%\n"
     ]
    }
   ],
   "source": [
    "# 5. Evaluate the Model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf57fba-d8f9-4413-8288-0d2a37455411",
   "metadata": {},
   "source": [
    "## Task 3: NLP with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7abc3998-597b-4a2d-a594-56e3de0dba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 Task 3: NLP using spaCy on Amazon Reviews\n",
    "\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51184eb6-3788-4c9d-bc5b-2abc8dcb2d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2330cf6b-ebdf-40c2-90ff-cb582c1b8cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (ensure 'reviews.csv' is downloaded from Kaggle and available)\n",
    "# This dataset should contain a 'reviewText' column\n",
    "df = pd.read_csv(\"amazon_reviews_sample.csv\")\n",
    "df = df.dropna(subset=['reviewText'])  # Remove missing reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13be36ab-bb42-4c1d-a32c-a3451349e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick 5 random sample reviews\n",
    "sample_reviews = df['reviewText'].sample(5, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "141bcd4f-df9f-48f5-b8de-99cbdacd2301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review: Highly recommend the Samsung Galaxy – it's so fast!\n",
      "Named Entities:\n",
      "Sentiment: Positive\n",
      "\n",
      "Review: Terrible product. The Apple charger stopped working in 2 days.\n",
      "Named Entities:\n",
      " - Apple (ORG)\n",
      " - 2 days (DATE)\n",
      "Sentiment: Negative\n",
      "\n",
      "Review: Not happy with the quality of this Nike shirt.\n",
      "Named Entities:\n",
      " - Nike (ORG)\n",
      "Sentiment: Negative\n",
      "\n",
      "Review: This Sony speaker has amazing sound quality!\n",
      "Named Entities:\n",
      " - Sony (ORG)\n",
      "Sentiment: Positive\n",
      "\n",
      "Review: The packaging for this Logitech mouse was great.\n",
      "Named Entities:\n",
      " - Logitech (ORG)\n",
      "Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "# Analyze each review\n",
    "for review in sample_reviews:\n",
    "    print(\"\\nReview:\", review)\n",
    "\n",
    "    # Named Entity Recognition\n",
    "    doc = nlp(review)\n",
    "    print(\"Named Entities:\")\n",
    "    for ent in doc.ents:\n",
    "        print(f\" - {ent.text} ({ent.label_})\")\n",
    "\n",
    "    # Sentiment Analysis using TextBlob\n",
    "    blob = TextBlob(review)\n",
    "    sentiment = \"Positive\" if blob.sentiment.polarity > 0 else \"Negative\" if blob.sentiment.polarity < 0 else \"Neutral\"\n",
    "    print(\"Sentiment:\", sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b356b03-0556-4bef-97e6-c3caba5cd2bf",
   "metadata": {},
   "source": [
    "# Part 3: Ethics & Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ac2516-6849-42ad-bba3-80745add9171",
   "metadata": {},
   "source": [
    "## 2. Troubleshooting Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d25dd9c7-7c92-424a-b81f-10178fbac178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03348367-fd64-481c-a504-2f2e28711428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd6d3aef-b1a8-4d0a-b2f0-4042a5c32718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocess the data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "934b2ca0-5d0e-41e5-8a90-13cd9d4e2cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape for CNN input: (samples, height, width, channels)\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac410077-32b9-4cca-82e2-c0b85a8e1e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # 10 output classes for MNIST\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22e32f22-f14b-46a0-85b1-58d54ba37ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Compile the model with proper loss function\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "399e2517-1e0b-4307-af2b-5d34e1baca7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 22ms/step - accuracy: 0.8947 - loss: 0.3382 - val_accuracy: 0.9810 - val_loss: 0.0665\n",
      "Epoch 2/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 27ms/step - accuracy: 0.9842 - loss: 0.0505 - val_accuracy: 0.9882 - val_loss: 0.0432\n",
      "Epoch 3/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 27ms/step - accuracy: 0.9887 - loss: 0.0342 - val_accuracy: 0.9878 - val_loss: 0.0435\n",
      "Epoch 4/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 27ms/step - accuracy: 0.9918 - loss: 0.0254 - val_accuracy: 0.9882 - val_loss: 0.0419\n",
      "Epoch 5/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 27ms/step - accuracy: 0.9941 - loss: 0.0181 - val_accuracy: 0.9902 - val_loss: 0.0409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1cd790ed450>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Train the model\n",
    "model.fit(x_train, y_train, epochs=5, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bf1a867-809f-4aad-b5c5-5e266a4d4a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9866 - loss: 0.0416\n",
      "Test Accuracy: 98.98%\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f81b5e-1754-400b-98c0-9f0846c6fbb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7960237b-7bdc-4e6a-875c-9da69c895ede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
